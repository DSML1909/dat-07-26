{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pandas Lab: Time Shifts & Multi Level Indexing\n",
    "\n",
    "This lab is designed to introduce you to working with time in a more granular way, and understanding how to build features when your data has hierarchies or panels.  \n",
    "\n",
    "Ie, when you have repeated observations for the same objects.  This is an important concept because lots of statistical methods don't explicitly account for values which might naturally be correlated with one another over time.  \n",
    "\n",
    "But lots of data **is** highly correlated over time!  \n",
    "\n",
    "By the time you're done with this lab, you'll have built 9 columns that capture a variety of information about how an observed value is changing with respect to itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1:** To capture some other aspects of dates, create columns in your dataset that capture the following aspects of each timestamp:\n",
    "\n",
    "  - What quarter it's in\n",
    "  - What month it's in\n",
    "  - What year it's in\n",
    "  - The number of days passed in the `visit_date` column\n",
    "\n",
    "If you want to try adding different pandas date parts, you can find them here:  https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html#time-date-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# you might have to change the file path\n",
    "df = pd.read_csv('../../data/restaurant_data/master.csv', parse_dates=['visit_date', 'calendar_date'])\n",
    "# sorting the values by the dates before you do this is not a bad idea\n",
    "df.sort_values(by=['id', 'visit_date'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['quarter'] = df['visit_date'].dt.quarter\n",
    "df['month']   = df['visit_date'].dt.month\n",
    "df['year']    = df['visit_date'].dt.year\n",
    "df['time']    = (df['visit_date'] - df['visit_date'].min()).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** Time Series Embedding\n",
    "\n",
    "Lots of times if you're trying to predict the value of something tomorrow, the most import piece of information is what the value of something is today, and yesterday, and so on.\n",
    "\n",
    "However, your data won't really \"know\" about those values unless they can be observed alongside the current observation.\n",
    "\n",
    "To that end, make three columns that capture the value of the following:\n",
    "\n",
    " - What the previous recorded attendance for the previous observation\n",
    " - The attendance from two observations ago\n",
    " - The attendance from 7 observations ago (ie, week over week)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "df['yesterday']    = df.groupby('id')['visitors'].shift()\n",
    "df['two_days_ago'] = df.groupby('id')['visitors'].shift(2)\n",
    "df['one_week_ago'] = df.groupby('id')['visitors'].shift(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bonus Answer:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create the date offsets\n",
    "one_day_ago  = pd.DateOffset(days=1)\n",
    "two_days_ago = pd.DateOffset(days=2)\n",
    "one_week_ago = pd.DateOffset(weeks=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and the groupings\n",
    "one_day_shift  = df.set_index('visit_date').groupby('id')[['visitors']].shift(freq=one_day_ago).rename({'visitors': 'one_day_ago'}, axis=1)\n",
    "two_days_shift = df.set_index('visit_date').groupby('id')[['visitors']].shift(freq=two_days_ago).rename({'visitors': 'two_days_ago_'}, axis=1)\n",
    "one_week_shift = df.set_index('visit_date').groupby('id')[['visitors']].shift(freq=one_week_ago).rename({'visitors': 'one_week_ago_'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge them back in \n",
    "df = df.merge(one_day_shift, left_on=['id', 'visit_date'], right_index=True, how='left')\n",
    "df = df.merge(two_days_shift, left_on=['id', 'visit_date'], right_index=True, how='left')\n",
    "df = df.merge(one_week_shift, left_on=['id', 'visit_date'], right_index=True, how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last three columns are the new ones we created -- might want to rename for clarity\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Window Statistics\n",
    "\n",
    "Lots of times, we want to capture some idea of momentum, or how some value changes with what's usually observed.\n",
    "\n",
    "Ie, if we had 48 purchases in a store today, how does that number compare to what's happened in the last 14 days?  Are things trending up or trending down?  \n",
    "\n",
    "This also allows us to get a clearer picture of general trends in values, even if there are irregular daily spikes.\n",
    "\n",
    "To handle these sorts of issues, pandas has an entire section to calculate window statistics called `rolling`, it works like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'll create a sample dataframe with 30 days worth of values\n",
    "import numpy as np\n",
    "index = pd.date_range(start='01/01/2020', end='02/05/2020')\n",
    "sample_df = pd.DataFrame(np.random.randn(36), index=index, columns=['Value'])\n",
    "# and here's what it looks like\n",
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and now we'll see rolling 10 day averages\n",
    "sample_df.rolling(10).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can specify the number of observations to calculate, and choose your aggregator -- `mean()`, `min()`, `sum()`, etc, although `mean()` is the most common."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Your Turn:** Calculate the rolling 7, 25, and 60 day moving averages for visits for each restaurant inside the dataset.\n",
    "\n",
    "And be mindful of performing these on the appropriate levels of your dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your answer here\n",
    "df['rolling_mean_7']  = df.groupby('id')['visitors'].rolling(7).mean().shift().values\n",
    "df['rolling_mean_25'] = df.groupby('id')['visitors'].rolling(25).mean().shift().values\n",
    "df['rolling_mean_60'] = df.groupby('id')['visitors'].rolling(60).mean().shift().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our final dataset\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One additional note:  for a calculation such as this is best if you shift the values up by one -- why might this be the case?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
